Binary search algorithm

In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array. If they are not equal, the half in which the target cannot lie is eliminated and the search continues on the remaining half, again taking the middle element to compare to the target value, and repeating this until the target value is found. If the search ends with the remaining half being empty, the target is not in the array. Even though the idea is simple, implementing binary search correctly requires attention to some subtleties about its exit conditions and midpoint calculation, particularly if the values in the array are not all of the whole numbers in the range.

Binary search runs in logarithmic time in the worst case, making comparisons, where is the number of elements in the array, the is Big O notation, and is the logarithm. Binary search takes constant () space, meaning that the space taken by the algorithm is the same for any number of elements in the array. Binary search is faster than linear search except for small arrays, but the array must be sorted first. Although specialized data structures designed for fast searching, such as hash tables, can be searched more efficiently, binary search applies to a wider range of problems.

There are numerous variations of binary search. In particular, fractional cascading speeds up binary searches for the same value in multiple arrays. Fractional cascading efficiently solves a number of search problems in computational geometry and in numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and B-tree data structures are based on binary search.

Binary search works on sorted arrays. Binary search begins by comparing the middle element of the array with the target value. If the target value matches the middle element, its position in the array is returned. If the target value is less than the middle element, the search continues in the lower half of the array. If the target value is greater than the middle element, the search continues in the upper half of the array. By doing this, the algorithm eliminates the half in which the target value cannot lie in each iteration.

Given an array formula_1 of formula_2 elements with values or records formula_3sorted such that formula_4, and target value formula_5, the following subroutine uses binary search to find the index of formula_5 in formula_1.

This iterative procedure keeps track of the search boundaries with the two variables formula_8 and formula_10. The procedure may be expressed in pseudocode as follows, where the variable names and types remain the same as above, codice_1 is the floor function, and codice_2 refers to a specific value that conveys the failure of the search.

In the above procedure, the algorithm checks whether the middle element (formula_13) is equal to the target (formula_5) in every iteration. Some implementations leave out this check during each iteration. The algorithm would perform this check only when one element is left (when formula_28). This results in a faster comparison loop, as one comparison is eliminated per iteration. However, it requires one more iteration on average.

Hermann Bottenbruch published the first implementation to leave out this check in 1962.


The procedure may return any index whose element is equal to the target value, even if there are duplicate elements in the array. For example, if the array to be searched was formula_45 and the target was formula_46, then it would be correct for the algorithm to either return the 4th (index 3) or 5th (index 4) element. The regular procedure would return the 4th element (index 3). However, it is sometimes necessary to find the leftmost element or the rightmost element if the target value is duplicated in the array. In the above example, the 4th element is the leftmost element of the value 4, while the 5th element is the rightmost element of the value 4. The alternative procedure above will always return the index of the rightmost element if an element is duplicated in the array.

To find the leftmost element, the following procedure can be used:


If formula_63 and formula_64, then formula_65 is the leftmost element that equals formula_5. Even if formula_5 is not in the array, formula_8 is the rank of formula_5 in the array, or the number of elements in the array that are less than formula_5.

Where codice_1 is the floor function, the pseudocode for this version is:

To find the rightmost element, the following procedure can be used:


If formula_87 and formula_88, then formula_89 is the rightmost element that equals formula_5. Even if "formula_5" is not in the array, formula_92 is the number of elements in the array that are greater than "formula_5".

Where codice_1 is the floor function, the pseudocode for this version is:

The above procedure only performs "exact" matches, finding the position of a target value. However, it is trivial to extend binary search to perform approximate matches because binary search operates on sorted arrays. For example, binary search can be used to compute, for a given value, its rank (the number of smaller elements), predecessor (next-smallest element), successor (next-largest element), and nearest neighbor. Range queries seeking the number of elements between two values can be performed with two rank queries.

The performance of binary search can be analyzed by reducing the procedure to a binary comparison tree. The root node of the tree is the middle element of the array. The middle element of the lower half is the left child node of the root and the middle element of the upper half is the right child node of the root. The rest of the tree is built in a similar fashion. This model represents binary search. Starting from the root node, the left or right subtrees are traversed depending on whether the target value is less or more than the node under consideration. This represents the successive elimination of elements.

In the worst case, binary search makes formula_98 iterations of the comparison loop, where the formula_99 notation denotes the floor function that yields the greatest integer less than or equal to the argument, and formula_100 is the binary logarithm. The worst case is reached when the search reaches the deepest level of the tree. This is equivalent to a binary search that has reduced to one element and always eliminates the smaller subarray out of the two in each iteration if they are not of equal size.

The worst case may also be reached when the target element is not in the array. If formula_101 is one less than a power of two, then this is always the case. Otherwise, the search may perform formula_98iterations if the search reaches the deepest level of the tree. However, it may make formula_103 iterations, which is one less than the worst case, if the search ends at the second-deepest level of the tree.

On average, assuming that each element is equally likely to be searched, binary search makes formula_104 iterations when the target element is in the array. This is approximately equal to formula_105 iterations. When the target element is not in the array, binary search makes formula_106 iterations on average, assuming that the range between and outside elements is equally likely to be searched.

In the best case, where the target value is the middle element of the array, its position is returned after one iteration.

In terms of iterations, no search algorithm that works only by comparing elements can exhibit better average and worst-case performance than binary search. The comparison tree representing binary search has the fewest levels possible as every level above the lowest level of the tree is filled completely. Otherwise, the search algorithm can eliminate few elements in an iteration, increasing the number of iterations required in the average and worst case. This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over "all" elements is worse than binary search. By dividing the array in half, binary search ensures that the size of both subarrays are as similar as possible.

The average number of iterations performed by binary search depends on the probability of each element being searched. The average case is different for successful searches and unsuccessful searches. It will be assumed that each element is equally likely to be searched for successful searches. For unsuccessful searches, it will be assumed that the intervals between and outside elements are equally likely to be searched. The average case for successful searches is the number of iterations required to search every element exactly once, divided by formula_2, the number of elements. The average case for unsuccessful searches is the number of iterations required to search an element within every interval exactly once, divided by the formula_108 intervals.

In the binary tree representation, a successful search can be represented by a path from the root to the target node, called an "internal path". The length of a path is the number of edges (connections between nodes) that the path passes through. The number of iterations performed by a search, given that the corresponding path has length formula_109, is formula_110 counting the initial iteration. The "internal path length" is the sum of the lengths of all unique internal paths. Since there is only one path from the root to any single node, each internal path represents a search for a specific element. If there are formula_2 elements, which is a positive integer, and the internal path length is formula_112, then the average number of iterations for a successful search formula_113, with the one iteration added to count the initial iteration.

Since binary search is the optimal algorithm for searching with comparisons, this problem is reduced to calculating the minimum internal path length of all binary trees with formula_2 nodes, which is equal to:

formula_115

For example, in a 7-element array, the root requires one iteration, the two elements below the root require two iterations, and the four elements below require three iterations. In this case, the internal path length is:

formula_116

The average number of iterations would be formula_117 based on the equation for the average case. The sum for formula_112 can be simplified to:

formula_119

Substituting the equation for formula_112 into the equation for formula_121:

formula_122

For integer formula_2, this is equivalent to the equation for the average case on a successful search specified above.

Unsuccessful searches can be represented by augmenting the tree with "external nodes", which forms an "extended binary tree". If an internal node, or a node present in the tree, has fewer than two child nodes, then additional child nodes, called external nodes, are added so that each internal node has two children. By doing so, an unsuccessful search can be represented as a path to an external node, whose parent is the single element that remains during the last iteration. An "external path" is a path from the root to an external node. The "external path length" is the sum of the lengths of all unique external paths. If there are formula_2 elements, which is a positive integer, and the external path length is formula_125, then the average number of iterations for an unsuccessful search formula_126. The external path length is divided by formula_127 instead of formula_2 because there are formula_127 external paths, representing the intervals between and outside the elements of the array.

This problem can similarly be reduced to determining the minimum external path length of all binary trees with formula_2 nodes. For all binary trees, the external path length is equal to the internal path length plus formula_131. Substituting the equation for formula_112:

formula_133

Substituting the equation for formula_125 into the equation for formula_135, the average case for unsuccessful searches can be determined:

formula_136

Each iteration of the binary search procedure defined above makes one or two comparisons, checking if the middle element is equal to the target in each iteration. Assuming that each element is equally likely to be searched, each iteration makes 1.5 comparisons on average. A variation of the algorithm checks whether the middle element is equal to the target at the end of the search. On average, this eliminates half a comparison from each iteration. This slightly cuts the time taken per iteration on most computers. However, it guarantees that the search takes the maximum number of iterations, on average adding one iteration to the search. Because the comparison loop is performed only formula_98 times in the worst case, the slight increase in efficiency per iteration does not compensate for the extra iteration for all but enormous formula_101.

Sorted arrays with binary search are a very inefficient solution when insertion and deletion operations are interleaved with retrieval, taking formula_139 time for each such operation. In addition, sorted arrays can complicate memory use especially when elements are often inserted into the array. There are other data structures that support much more efficient insertion and deletion. Binary search can be used to perform exact matching and set membership (determining whether a target value is in a collection of values). There are data structures that support faster exact matching and set membership. However, unlike many other searching schemes, binary search can be used for efficient approximate matching, usually performing such matches in formula_140 time regardless of the type or structure of the values themselves. In addition, there are some operations, like finding the smallest and largest element, that can be performed efficiently on a sorted array.

For implementing associative arrays, hash tables, a data structure that maps keys to records using a hash function, are generally faster than binary search on a sorted array of records. Most hash table implementations require only amortized constant time on average. However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, as the only information given on a failed search is that the target is not present in any record. Binary search is ideal for such matches, performing them in logarithmic time. Binary search also supports approximate matches. Some operations, like finding the smallest and largest element, can be done efficiently on sorted arrays but not on hash tables.

A binary search tree is a binary tree data structure that works based on the principle of binary search. The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to binary search, taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in binary search trees. This can be faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries.

However, binary search is usually more efficient for searching as binary search trees will most likely be imperfectly balanced, resulting in slightly worse performance than binary search. This even applies to balanced binary search trees, binary search trees that balance their own nodes, because they rarely produce "optimally"-balanced trees. Although unlikely, the tree may be severely imbalanced with few internal nodes with two children, resulting in the average and worst-case search time approaching formula_101 comparisons. Binary search trees take more space than sorted arrays.

Binary search trees lend themselves to fast searching in external memory stored in hard disks, as binary search trees can efficiently be structured in filesystems. The B-tree generalizes this method of tree organization. B-trees are frequently used to organize long-term storage such as databases and filesystems.

Linear search is a simple search algorithm that checks every record until it finds the target value. Linear search can be done on a linked list, which allows for faster insertion and deletion than an array. Binary search is faster than linear search for sorted arrays except if the array is short, although the array needs to be sorted beforehand. All sorting algorithms based on comparing elements, such as quicksort and merge sort, require at least formula_142 comparisons in the worst case. Unlike linear search, binary search can be used for efficient approximate matching. There are operations such as finding the smallest and largest element that can be done efficiently on a sorted array but not on an unsorted array.

A related problem to search is set membership. Any algorithm that does lookup, like binary search, can also be used for set membership. There are other algorithms that are more specifically suited for set membership. A bit array is the simplest, useful when the range of keys is limited. It compactly stores a collection of bits, with each bit representing a single key within the range of keys. Bit arrays are very fast, requiring only formula_143 time. The Judy1 type of Judy array handles 64-bit keys efficiently.

For approximate results, Bloom filters, another probabilistic data structure based on hashing, store a set of keys by encoding the keys using a bit array and multiple hash functions. Bloom filters are much more space-efficient than bit arrays in most cases and not much slower: with formula_144 hash functions, membership queries require only formula_145 time. However, Bloom filters suffer from false positives.

There exist data structures that may improve on binary search in some cases for both searching and other operations available for sorted arrays. For example, searches, approximate matches, and the operations available to sorted arrays can be performed more efficiently than binary search on specialized data structures such as van Emde Boas trees, fusion trees, tries, and bit arrays. These specialized data structures are usually only faster because they take advantage of the properties of keys with a certain attribute (usually keys that are small integers), and thus will be time or space consuming for keys that lack that attribute. As long as the keys can be ordered, these operations can always be done at least efficiently on a sorted array regardless of the keys. Some structures, such as Judy arrays, use a combination of approaches to mitigate this while retaining efficiency and the ability to perform approximate matching.

Uniform binary search stores, instead of the lower and upper bounds, the index of the middle element and the change in the middle element from the current iteration to the next iteration. Each step reduces the change by about half. For example, if the array to be searched is formula_146, the middle element would be formula_147. Uniform binary search works on the basis that the difference between the index of middle element of the array and the left and right subarrays is the same. In this case, the middle element of the left subarray (formula_148) is formula_149 and the middle element of the right subarray (formula_150) is formula_151. Uniform binary search would store the value of formula_149 as both indices differ from formula_147 by this same amount. To reduce the search space, the algorithm either adds or subtracts this change from the middle element. The main advantage of uniform binary search is that the procedure can store a table of the differences between indices for each iteration of the procedure. Uniform binary search may be faster on systems where it is inefficient to calculate the midpoint, such as on decimal computers.

Exponential search extends binary search to unbounded lists. It starts by finding the first element with an index that is both a power of two and greater than the target value. Afterwards, it sets that index as the upper bound, and switches to binary search. A search takes formula_154 iterations of the exponential search and at most formula_155 iterations of the binary search, where formula_156 is the position of the target value. Exponential search works on bounded lists, but becomes an improvement over binary search only if the target value lies near the beginning of the array.

Instead of calculating the midpoint, interpolation search estimates the position of the target value, taking into account the lowest and highest elements in the array as well as length of the array. This is only possible if the array elements are numbers. It works on the basis that the midpoint is not the best guess in many cases. For example, if the target value is close to the highest element in the array, it is likely to be located near the end of the array. When the distribution of the array elements is uniform or near uniform, it makes formula_157 comparisons.

In practice, interpolation search is slower than binary search for small arrays, as interpolation search requires extra computation. Its time complexity grows more slowly than binary search, but this only compensates for the extra computation for large arrays.

Fractional cascading is a technique that speeds up binary searches for the same element in multiple sorted arrays. Searching each array separately requires formula_158 time, where formula_144 is the number of arrays. Fractional cascading reduces this to formula_160 by storing specific information in each array about each element and its position in the other arrays.

Fractional cascading was originally developed to efficiently solve various computational geometry problems. Fractional cascading has been applied elsewhere, such as in data mining and Internet Protocol routing.

Noisy binary search algorithms solve the case where the algorithm cannot reliably compare elements of the array. For each pair of elements, there is a certain probability that the algorithm makes the wrong comparison. Noisy binary search can find the correct position of the target with a given probability that controls the reliability of the yielded position.

Classical computers are bounded to the worst case of exactly formula_161 iterations when performing binary search. Quantum algorithms for binary search are still bounded to a proportion of formula_162 queries (representing iterations of the classical procedure), but the constant factor is less than one, providing for faster performance on quantum computers. Any "exact" quantum binary search procedure—that is, a procedure that always yields the correct result—requires at least formula_163 queries in the worst case, where formula_164 is the natural logarithm. There is an exact quantum binary search procedure that runs in formula_165 queries in the worst case. In comparison, Grover's algorithm is the optimal quantum algorithm for searching an unordered list of elements, and it requires formula_166 queries.

In 1946, John Mauchly made the first mention of binary search as part of the Moore School Lectures, a seminal and foundational college course in computing. In 1957, William Wesley Peterson published the first method for interpolation search. Every published binary search algorithm worked only for arrays whose length is one less than a power of two until 1960, when Derrick Henry Lehmer published a binary search algorithm that worked on all arrays. In 1962, Hermann Bottenbruch presented an ALGOL 60 implementation of binary search that placed the comparison for equality at the end, increasing the average number of iterations by one, but reducing to one the number of comparisons per iteration. The uniform binary search was developed by A. K. Chandra of Stanford University in 1971. In 1986, Bernard Chazelle and Leonidas J. Guibas introduced fractional cascading as a method to solve numerous search problems in computational geometry.

Although the basic idea of binary search is comparatively straightforward, the details can be surprisingly tricky ... — Donald Knuth

When Jon Bentley assigned binary search as a problem in a course for professional programmers, he found that ninety percent failed to provide a correct solution after several hours of working on it, mainly because the incorrect implementations failed to run or returned a wrong answer in rare edge cases. A study published in 1988 shows that accurate code for it is only found in five out of twenty textbooks. Furthermore, Bentley's own implementation of binary search, published in his 1986 book "Programming Pearls", contained an overflow error that remained undetected for over twenty years. The Java programming language library implementation of binary search had the same overflow bug for more than nine years.

In a practical implementation, the variables used to represent the indices will often be of fixed size, and this can result in an arithmetic overflow for very large arrays. If the midpoint of the span is calculated as formula_14, then the value of formula_168 may exceed the range of integers of the data type used to store the midpoint, even if formula_8 and formula_10 are within the range. If "formula_8" and "formula_10" are nonnegative, this can be avoided by calculating the midpoint as formula_173.

If the target value is greater than the greatest value in the array, and the last index of the array is the maximum representable value of "formula_8", the value of "formula_8" will eventually become too large and overflow. A similar problem will occur if the target value is smaller than the least value in the array and the first index of the array is the smallest representable value of "formula_10". In particular, this means that "formula_10" must not be an unsigned type if the array starts with index formula_9.

An infinite loop may occur if the exit conditions for the loop are not defined correctly. Once "formula_8" exceeds "formula_10", the search has failed and must convey the failure of the search. In addition, the loop must be exited when the target element is found, or in the case of an implementation where this check is moved to the end, checks for whether the search was successful or failed at the end must be in place. Bentley found that most of the programmers who incorrectly implemented binary search made an error in defining the exit conditions.

Many languages' standard libraries include binary search routines:




